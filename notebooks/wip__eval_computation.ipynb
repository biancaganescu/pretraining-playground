{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 77/77 [00:01<00:00, 55.60it/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dataset = load_dataset(\n",
    "    \"rdiehlmartinez/pythia-pile-presampled\",\n",
    "    \"checkpoints\",\n",
    "    split='train',\n",
    ")\n",
    "\n",
    "model_sizes = [\"70m\", \"160m\", \"410m\", \"1b\", \"1.4b\", \"2.8b\"]\n",
    "\n",
    "# checkpoint step stored by pythia \n",
    "\n",
    "# checkpointing steps used in evaluation by pythia \n",
    "checkpoint_steps = [0, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1000, ]\n",
    "checkpoint_steps.extend([3000 + (i * 10000) for i in range(0, 15)])\n",
    "\n",
    "ORIGINAL_BATCH_SIZE = 1024 \n",
    "REDUCED_BATCH_SIZE = 128 \n",
    "\n",
    "MAX_STEP = 142_999 # Last step in training (used to index final batc)\n",
    "\n",
    "# NOTE: setting up the data batch sizes \n",
    "\n",
    "ordered_steps = list(set(checkpoint_dataset['step']))\n",
    "ordered_steps.sort()\n",
    "step_to_start_index = {step: i*1024 for i, step in enumerate(ordered_steps)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_batch(step, include_labels=True):\n",
    "    \"\"\"\n",
    "    Get a data batch for a given step in the training process.\n",
    "    \"\"\"\n",
    "\n",
    "    assert(step in step_to_start_index), f\"Step {step} not valid checkpoint step.\"\n",
    "    start_idx = step_to_start_index[step]\n",
    "    end_idx = start_idx + 1024\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(checkpoint_dataset[start_idx:end_idx]['ids'], device='cuda'),\n",
    "        \"labels\": torch.tensor(checkpoint_dataset[start_idx:end_idx]['ids'], device='cuda') if include_labels else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rd654/.cache/pypoetry/virtualenvs/pretraining-playground-YJRPv6z4-py3.10/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_size = \"70m\"\n",
    "checkpoint_step = 1000\n",
    "\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "    f\"EleutherAI/pythia-{model_size}-deduped\",\n",
    "    revision=f\"step{checkpoint_step}\",\n",
    "    cache_dir=f\"./pythia-{model_size}-deduped/step{checkpoint_step}\",\n",
    ").to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch = get_data_batch(checkpoint_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'labels'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, batch, debug=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform a forward pass of the model on a given batch of data; assumes that the model \n",
    "    has hooks setup to save the hidden states at each layer.\n",
    "    \"\"\"\n",
    "    if debug:\n",
    "        torch.cuda.memory._record_memory_history(max_entries=100000)\n",
    "        # split up the last batch into smaller batches that can fit on the GPU \n",
    "        # automatically find the largest batch size that can fit on the GPU\n",
    "        # and then use that to split up the last batch\n",
    "\n",
    "    batch_index = 0\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    batch_size = 1\n",
    "    static_batch_size = None # NOTE: static_batch_size is only set when batch size is reduced\n",
    "\n",
    "    while batch_index < REDUCED_BATCH_SIZE:\n",
    "\n",
    "        if verbose:\n",
    "            print(\"START OF LOOP\")\n",
    "            print(\"memory: \", torch.cuda.memory_allocated()/1e9, \"GB\")\n",
    "\n",
    "        try:\n",
    "            if static_batch_size is None:\n",
    "                _batch_size = batch_size\n",
    "            else: \n",
    "                # NOTE: reached when we've run out of memory and have reduced the batch size\n",
    "                _batch_size = static_batch_size\n",
    "\n",
    "            batch_end_index = min(batch_index + _batch_size, REDUCED_BATCH_SIZE)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Batch index: {batch_index}, Batch end index: {batch_end_index}\")\n",
    "                print(f\"Batch size: {_batch_size}\")\n",
    "\n",
    "            _inputs = batch['input_ids'][batch_index : batch_end_index]\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Shape of current sub-batch inputs: {_inputs.shape}\")\n",
    "\n",
    "            _labels = batch['labels'][batch_index : batch_end_index]\n",
    "\n",
    "            if verbose:\n",
    "                print(\"AFTER INPUTS\")\n",
    "                print(\"memory: \", torch.cuda.memory_allocated()/1e9, \"GB\")\n",
    "\n",
    "            _loss = model(_inputs, labels=_labels).loss.item()\n",
    "\n",
    "            if verbose:\n",
    "                print(\"AFTER MODEL\")\n",
    "                print(\"memory: \", torch.cuda.memory_allocated()/1e9, \"GB\")\n",
    "\n",
    "        except RuntimeError:\n",
    "            # NOTE: Exception is thrown when the batch size is too large for the GPU\n",
    "\n",
    "            if batch_size == 1:\n",
    "                raise Exception(\"Batch size of 1 is too large for the GPU\")\n",
    "\n",
    "            _batch_size //= 2\n",
    "            static_batch_size = _batch_size\n",
    "            if verbose:\n",
    "                print(f\"Reducing batch size to: {_batch_size}\")\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            continue\n",
    "\n",
    "        total_loss += _loss * _batch_size\n",
    "\n",
    "        batch_index = batch_end_index\n",
    "\n",
    "        if static_batch_size is None:\n",
    "            batch_size *= 2\n",
    "\n",
    "    if debug:\n",
    "        torch.cuda.memory._dump_snapshot(\"memory_snapshot_NA.pickle\")\n",
    "        torch.cuda.memory._record_memory_history(enabled=None)\n",
    "\n",
    "    return total_loss/REDUCED_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 0, Batch end index: 1\n",
      "Batch size: 1\n",
      "Shape of current sub-batch inputs: torch.Size([1, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 1, Batch end index: 3\n",
      "Batch size: 2\n",
      "Shape of current sub-batch inputs: torch.Size([2, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 3, Batch end index: 7\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 7, Batch end index: 15\n",
      "Batch size: 8\n",
      "Shape of current sub-batch inputs: torch.Size([8, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "Reducing batch size to: 4\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 7, Batch end index: 11\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 11, Batch end index: 15\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 15, Batch end index: 19\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 19, Batch end index: 23\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 23, Batch end index: 27\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 27, Batch end index: 31\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 31, Batch end index: 35\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 35, Batch end index: 39\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 39, Batch end index: 43\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 43, Batch end index: 47\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 47, Batch end index: 51\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 51, Batch end index: 55\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 55, Batch end index: 59\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 59, Batch end index: 63\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 63, Batch end index: 67\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 67, Batch end index: 71\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 71, Batch end index: 75\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 75, Batch end index: 79\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 79, Batch end index: 83\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 83, Batch end index: 87\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 87, Batch end index: 91\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 91, Batch end index: 95\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 95, Batch end index: 99\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 99, Batch end index: 103\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 103, Batch end index: 107\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 107, Batch end index: 111\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 111, Batch end index: 115\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 115, Batch end index: 119\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 119, Batch end index: 123\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 123, Batch end index: 127\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([4, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n",
      "START OF LOOP\n",
      "memory:  71.414570496 GB\n",
      "Batch index: 127, Batch end index: 128\n",
      "Batch size: 4\n",
      "Shape of current sub-batch inputs: torch.Size([1, 2049])\n",
      "AFTER INPUTS\n",
      "memory:  71.414570496 GB\n",
      "AFTER MODEL\n",
      "memory:  71.414570496 GB\n"
     ]
    }
   ],
   "source": [
    "total_loss = forward_pass(model, data_batch, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.699067138135433"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_batch = {\n",
    "    \"input_ids\": data_batch['input_ids'][:8],\n",
    "    \"labels\": data_batch['labels'][:8]\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(**sub_batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.837646007537842"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXConfig {\n",
       "  \"_name_or_path\": \"EleutherAI/pythia-70m-deduped\",\n",
       "  \"architectures\": [\n",
       "    \"GPTNeoXForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": true,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": 0.1,\n",
       "  \"eos_token_id\": 0,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout\": 0.0,\n",
       "  \"hidden_size\": 512,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 2048,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"gpt_neox\",\n",
       "  \"num_attention_heads\": 8,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rotary_emb_base\": 10000,\n",
       "  \"rotary_pct\": 0.25,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.37.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_parallel_residual\": true,\n",
       "  \"vocab_size\": 50304\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get max context length of model \n",
    "model.config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretraining-playground-YJRPv6z4-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
