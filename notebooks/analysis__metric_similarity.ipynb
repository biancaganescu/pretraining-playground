{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Metric (Feature) Similarity Analysis \n",
    "\n",
    "Trying to understand how intercorrelated the metrics are via computing the PCA dim. reduction of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from utils import MODEL_SIZES, CHECKPOINT_STEPS, METRICS, sort_and_filter_metrics\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import scipy.stats\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Model Size:  70m\n",
      "FOR AVERAGE METRICS\n",
      "Explained variance ratio [0.74326579 0.13973215 0.10877259 0.00822947]\n",
      "FOR INDIVIDUAL METRICS\n",
      "Explained variance ratio [7.08622485e-01 1.46866678e-01 1.13558965e-01 1.02518490e-02\n",
      " 7.01739349e-03 4.86872938e-03 3.65475421e-03 1.86811918e-03\n",
      " 1.29559746e-03 8.60086444e-04 5.41919248e-04 1.96732854e-04\n",
      " 1.43106950e-04 1.15740409e-04 4.95495155e-05 3.76378357e-05\n",
      " 2.47386013e-05 1.68063964e-05 5.85134269e-06 1.53380610e-06\n",
      " 1.28544475e-06 4.16846700e-07 2.25004174e-08 5.75614632e-10]\n",
      "---\n",
      "---\n",
      "Model Size:  160m\n",
      "FOR AVERAGE METRICS\n",
      "Explained variance ratio [0.73922439 0.13563861 0.1068667  0.0182703 ]\n",
      "FOR INDIVIDUAL METRICS\n",
      "Explained variance ratio [7.06977355e-01 1.38819092e-01 1.08576694e-01 1.82107612e-02\n",
      " 1.32203830e-02 4.74010667e-03 3.79002244e-03 1.79039952e-03\n",
      " 1.32288448e-03 7.61404354e-04 5.62349287e-04 5.10667927e-04\n",
      " 2.24490276e-04 1.55922088e-04 1.27314264e-04 6.83556654e-05\n",
      " 6.11621300e-05 3.03440453e-05 1.94205109e-05 1.30458321e-05\n",
      " 9.96873647e-06 4.81908074e-06 2.80348979e-06 2.34076458e-07\n",
      " 3.21218617e-13 1.39426699e-31 6.56098234e-33]\n",
      "---\n",
      "---\n",
      "Model Size:  410m\n",
      "FOR AVERAGE METRICS\n",
      "Explained variance ratio [0.80404371 0.12736597 0.05891489 0.00967543]\n",
      "FOR INDIVIDUAL METRICS\n",
      "Explained variance ratio [7.62469214e-01 1.22541054e-01 8.25416013e-02 1.08536973e-02\n",
      " 7.76110770e-03 7.09487048e-03 2.42280008e-03 1.40061278e-03\n",
      " 1.01996752e-03 5.75421782e-04 4.14340571e-04 2.64828888e-04\n",
      " 2.01151655e-04 1.28266402e-04 9.69494032e-05 6.56139528e-05\n",
      " 4.27014994e-05 3.75912708e-05 2.44991146e-05 2.06384792e-05\n",
      " 1.08477304e-05 9.07305120e-06 2.35534485e-06 7.96379848e-07\n",
      " 7.42423111e-11 1.50370539e-31 6.68490634e-33]\n",
      "---\n",
      "---\n",
      "Model Size:  1.4b\n",
      "FOR AVERAGE METRICS\n",
      "Explained variance ratio [0.79936362 0.14105854 0.04812699 0.01145085]\n",
      "FOR INDIVIDUAL METRICS\n",
      "Explained variance ratio [7.76911548e-01 1.35386233e-01 6.47790735e-02 1.22944713e-02\n",
      " 5.22870179e-03 2.26307126e-03 8.90205947e-04 6.25642996e-04\n",
      " 4.69695376e-04 3.02863023e-04 2.13181017e-04 1.89356499e-04\n",
      " 1.17207915e-04 9.51271636e-05 7.40588625e-05 5.72925717e-05\n",
      " 4.61492598e-05 2.20099282e-05 1.19904935e-05 8.30303409e-06\n",
      " 6.10036308e-06 4.43542104e-06 2.69604064e-06 5.84768917e-07\n",
      " 1.10321932e-10 1.12767611e-32 6.64644626e-33]\n",
      "---\n",
      "---\n",
      "Model Size:  2.8b\n",
      "FOR AVERAGE METRICS\n",
      "Explained variance ratio [0.82914398 0.14005706 0.02148722 0.00931175]\n",
      "FOR INDIVIDUAL METRICS\n",
      "Explained variance ratio [8.16965844e-01 1.39203319e-01 2.58459983e-02 1.23555382e-02\n",
      " 2.34085059e-03 1.29145461e-03 7.94272415e-04 3.41081299e-04\n",
      " 2.31468649e-04 1.73846995e-04 1.46122463e-04 1.19446848e-04\n",
      " 8.02604452e-05 3.38697189e-05 2.37337744e-05 1.84860436e-05\n",
      " 1.08258617e-05 9.23240887e-06 4.59264970e-06 3.56393469e-06\n",
      " 2.19962426e-06 1.87682027e-06 1.37305849e-06 7.40797171e-07\n",
      " 1.41439945e-09 1.45579251e-20 6.75509379e-33]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for model_size in MODEL_SIZES:\n",
    "        \n",
    "    # Setting up a matrix of the features\n",
    "    X_avg = np.zeros((len(CHECKPOINT_STEPS), len(METRICS)))\n",
    "    X = []\n",
    "\n",
    "    for metric_idx, metric_name in enumerate(METRICS):\n",
    "        with open(f'/home/rd654/pretraining-playground/computed_statistics/{model_size}/{metric_name}_per_layer.pkl', 'rb') as f:\n",
    "            _metrics = pickle.load(f)\n",
    "            # filter out only attention.dense and dense_4h_to_h layers \n",
    "            metrics = sort_and_filter_metrics(_metrics, filter_layer_name=\"ov_circuit\", remove_heads=True)\n",
    "        \n",
    "        # NOTE: I'm not sure if I should do the SVD analysis on the average of the metrics or the individual metrics\n",
    "        # maybe we just do both \n",
    "        \n",
    "        X_curr = np.zeros((len(CHECKPOINT_STEPS), len(metrics)))\n",
    "\n",
    "        layer_average_metric = None\n",
    "\n",
    "        for layer_idx, (layer_name, layer_checkpoint_metrics) in enumerate(metrics.items()):\n",
    "            if layer_average_metric is None:\n",
    "                layer_average_metric = np.zeros(len(layer_checkpoint_metrics))\n",
    "            \n",
    "            layer_average_metric += np.array(layer_checkpoint_metrics)\n",
    " \n",
    "            X_curr[:, layer_idx] = layer_checkpoint_metrics\n",
    "\n",
    "        layer_average_metric /= len(metrics)\n",
    "\n",
    "        X_avg[:, metric_idx] = layer_average_metric\n",
    "        X.append(X_curr)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_avg_scaled = scaler.fit_transform(X_avg)\n",
    "    scaler = StandardScaler()\n",
    "    # concatenate column wise X \n",
    "    X = np.concatenate(X, axis=1)\n",
    "\n",
    "    #print out shape of X \n",
    "\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"---\")\n",
    "    print(\"Model Size: \", model_size)\n",
    "\n",
    "    print(\"FOR AVERAGE METRICS\")\n",
    "    pca = PCA()\n",
    "    pca.fit_transform(X_avg_scaled)\n",
    "    # print(\"Principal coponents\", pca.components_)\n",
    "    print(\"Explained variance ratio\", pca.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "    print(\"FOR INDIVIDUAL METRICS\")\n",
    "    pca = PCA()\n",
    "    pca.fit_transform(X_scaled)\n",
    "    # print(\"Principal components\", pca.components_)\n",
    "    print(\"Explained variance ratio\", pca.explained_variance_ratio_)\n",
    "    print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Correlation between metric features \n",
    "\n",
    "Computing pair-wise linear correlation between features: cka scores and grad sim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size:  70m\n",
      "Average Linear Correlation Coeff.:  -0.6276919088769429\n",
      "Average R2 Value:  0.4432594070524094\n",
      "Model Size:  160m\n",
      "Average Linear Correlation Coeff.:  -0.5753619207366213\n",
      "Average R2 Value:  0.40801597560499075\n",
      "Model Size:  410m\n",
      "Average Linear Correlation Coeff.:  -0.6826211517859152\n",
      "Average R2 Value:  0.5650402215908864\n",
      "Model Size:  1.4b\n",
      "Average Linear Correlation Coeff.:  -0.7623811199228662\n",
      "Average R2 Value:  0.6225179999027586\n",
      "Model Size:  2.8b\n",
      "Average Linear Correlation Coeff.:  -0.8738087147348669\n",
      "Average R2 Value:  0.7729885114202066\n"
     ]
    }
   ],
   "source": [
    "for model_size in MODEL_SIZES:\n",
    "\n",
    "    # NOTE: computing the linear correlation between the cka_scores and grad_sim\n",
    "\n",
    "    cka_scores, grad_sim = None, None\n",
    "\n",
    "    for metric_name in [\"cka_scores\", \"grad_sim\"]:\n",
    "        with open(f'/home/rd654/pretraining-playground/computed_statistics/{model_size}/{metric_name}_per_layer.pkl', 'rb') as f:\n",
    "            _metrics = pickle.load(f)\n",
    "            # filter out only attention.dense and dense_4h_to_h layers \n",
    "            metrics = sort_and_filter_metrics(_metrics, filter_layer_name=\"ov_circuit\", remove_heads=True)\n",
    "\n",
    "        if metric_name == \"cka_scores\":\n",
    "            cka_scores = metrics\n",
    "        else:\n",
    "            grad_sim = metrics\n",
    "   \n",
    "    avg_corr_coeff = 0\n",
    "    avg_r2 = 0\n",
    "\n",
    "    for layer in cka_scores.keys():\n",
    "\n",
    "        corr_coeff = scipy.stats.pearsonr(cka_scores[layer], grad_sim[layer])[0]\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(cka_scores[layer], grad_sim[layer])\n",
    "\n",
    "        avg_corr_coeff += corr_coeff\n",
    "        avg_r2 += r_value**2\n",
    "\n",
    "    avg_corr_coeff /= len(cka_scores)\n",
    "    avg_r2 /= len(cka_scores)\n",
    "    \n",
    "    print(\"Model Size: \", model_size)\n",
    "    print(\"Average Linear Correlation Coeff.: \", avg_corr_coeff)\n",
    "    print(\"Average R2 Value: \", avg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretraining-playground-YJRPv6z4-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
