{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPTNeoXForCausalLM, GPTNeoXTokenizerFast\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# open model_metris/70m/checkpoint_1\n",
    "with open('model_metrics/70m/checkpoint_0/state_metrics.pickle', 'rb') as f:\n",
    "    model_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_activations\n",
      "gpt_neox.layers.0.attention.query_key_value\n",
      "gpt_neox.layers.0.attention.dense\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h\n",
      "gpt_neox.layers.1.attention.query_key_value\n",
      "gpt_neox.layers.1.attention.dense\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h\n",
      "gpt_neox.layers.2.attention.query_key_value\n",
      "gpt_neox.layers.2.attention.dense\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h\n",
      "gpt_neox.layers.3.attention.query_key_value\n",
      "gpt_neox.layers.3.attention.dense\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h\n",
      "gpt_neox.layers.4.attention.query_key_value\n",
      "gpt_neox.layers.4.attention.dense\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h\n",
      "gpt_neox.layers.5.attention.query_key_value\n",
      "gpt_neox.layers.5.attention.dense\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h\n",
      "Total number of parameters: 1179648\n",
      "Total memory size: 4.5 MB\n",
      "checkpoint_weights\n",
      "gpt_neox.layers.0.attention.query_key_value\n",
      "gpt_neox.layers.0.attention.dense\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h\n",
      "gpt_neox.layers.1.attention.query_key_value\n",
      "gpt_neox.layers.1.attention.dense\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h\n",
      "gpt_neox.layers.2.attention.query_key_value\n",
      "gpt_neox.layers.2.attention.dense\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h\n",
      "gpt_neox.layers.3.attention.query_key_value\n",
      "gpt_neox.layers.3.attention.dense\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h\n",
      "gpt_neox.layers.4.attention.query_key_value\n",
      "gpt_neox.layers.4.attention.dense\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h\n",
      "gpt_neox.layers.5.attention.query_key_value\n",
      "gpt_neox.layers.5.attention.dense\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h\n",
      "Total number of parameters: 12582912\n",
      "Total memory size: 48.0 MB\n",
      "checkpoint_gradients\n",
      "0\n",
      "gpt_neox.layers.0.attention.query_key_value.weight\n",
      "gpt_neox.layers.0.attention.query_key_value.bias\n",
      "gpt_neox.layers.0.attention.dense.weight\n",
      "gpt_neox.layers.0.attention.dense.bias\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.1.attention.query_key_value.weight\n",
      "gpt_neox.layers.1.attention.query_key_value.bias\n",
      "gpt_neox.layers.1.attention.dense.weight\n",
      "gpt_neox.layers.1.attention.dense.bias\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.2.attention.query_key_value.weight\n",
      "gpt_neox.layers.2.attention.query_key_value.bias\n",
      "gpt_neox.layers.2.attention.dense.weight\n",
      "gpt_neox.layers.2.attention.dense.bias\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.3.attention.query_key_value.weight\n",
      "gpt_neox.layers.3.attention.query_key_value.bias\n",
      "gpt_neox.layers.3.attention.dense.weight\n",
      "gpt_neox.layers.3.attention.dense.bias\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.4.attention.query_key_value.weight\n",
      "gpt_neox.layers.4.attention.query_key_value.bias\n",
      "gpt_neox.layers.4.attention.dense.weight\n",
      "gpt_neox.layers.4.attention.dense.bias\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.5.attention.query_key_value.weight\n",
      "gpt_neox.layers.5.attention.query_key_value.bias\n",
      "gpt_neox.layers.5.attention.dense.weight\n",
      "gpt_neox.layers.5.attention.dense.bias\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.bias\n",
      "1\n",
      "gpt_neox.layers.0.attention.query_key_value.weight\n",
      "gpt_neox.layers.0.attention.query_key_value.bias\n",
      "gpt_neox.layers.0.attention.dense.weight\n",
      "gpt_neox.layers.0.attention.dense.bias\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.1.attention.query_key_value.weight\n",
      "gpt_neox.layers.1.attention.query_key_value.bias\n",
      "gpt_neox.layers.1.attention.dense.weight\n",
      "gpt_neox.layers.1.attention.dense.bias\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.2.attention.query_key_value.weight\n",
      "gpt_neox.layers.2.attention.query_key_value.bias\n",
      "gpt_neox.layers.2.attention.dense.weight\n",
      "gpt_neox.layers.2.attention.dense.bias\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.3.attention.query_key_value.weight\n",
      "gpt_neox.layers.3.attention.query_key_value.bias\n",
      "gpt_neox.layers.3.attention.dense.weight\n",
      "gpt_neox.layers.3.attention.dense.bias\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.4.attention.query_key_value.weight\n",
      "gpt_neox.layers.4.attention.query_key_value.bias\n",
      "gpt_neox.layers.4.attention.dense.weight\n",
      "gpt_neox.layers.4.attention.dense.bias\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.5.attention.query_key_value.weight\n",
      "gpt_neox.layers.5.attention.query_key_value.bias\n",
      "gpt_neox.layers.5.attention.dense.weight\n",
      "gpt_neox.layers.5.attention.dense.bias\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.bias\n",
      "2\n",
      "gpt_neox.layers.0.attention.query_key_value.weight\n",
      "gpt_neox.layers.0.attention.query_key_value.bias\n",
      "gpt_neox.layers.0.attention.dense.weight\n",
      "gpt_neox.layers.0.attention.dense.bias\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.1.attention.query_key_value.weight\n",
      "gpt_neox.layers.1.attention.query_key_value.bias\n",
      "gpt_neox.layers.1.attention.dense.weight\n",
      "gpt_neox.layers.1.attention.dense.bias\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.2.attention.query_key_value.weight\n",
      "gpt_neox.layers.2.attention.query_key_value.bias\n",
      "gpt_neox.layers.2.attention.dense.weight\n",
      "gpt_neox.layers.2.attention.dense.bias\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.3.attention.query_key_value.weight\n",
      "gpt_neox.layers.3.attention.query_key_value.bias\n",
      "gpt_neox.layers.3.attention.dense.weight\n",
      "gpt_neox.layers.3.attention.dense.bias\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.4.attention.query_key_value.weight\n",
      "gpt_neox.layers.4.attention.query_key_value.bias\n",
      "gpt_neox.layers.4.attention.dense.weight\n",
      "gpt_neox.layers.4.attention.dense.bias\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.5.attention.query_key_value.weight\n",
      "gpt_neox.layers.5.attention.query_key_value.bias\n",
      "gpt_neox.layers.5.attention.dense.weight\n",
      "gpt_neox.layers.5.attention.dense.bias\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.bias\n",
      "3\n",
      "gpt_neox.layers.0.attention.query_key_value.weight\n",
      "gpt_neox.layers.0.attention.query_key_value.bias\n",
      "gpt_neox.layers.0.attention.dense.weight\n",
      "gpt_neox.layers.0.attention.dense.bias\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.1.attention.query_key_value.weight\n",
      "gpt_neox.layers.1.attention.query_key_value.bias\n",
      "gpt_neox.layers.1.attention.dense.weight\n",
      "gpt_neox.layers.1.attention.dense.bias\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.2.attention.query_key_value.weight\n",
      "gpt_neox.layers.2.attention.query_key_value.bias\n",
      "gpt_neox.layers.2.attention.dense.weight\n",
      "gpt_neox.layers.2.attention.dense.bias\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.3.attention.query_key_value.weight\n",
      "gpt_neox.layers.3.attention.query_key_value.bias\n",
      "gpt_neox.layers.3.attention.dense.weight\n",
      "gpt_neox.layers.3.attention.dense.bias\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.4.attention.query_key_value.weight\n",
      "gpt_neox.layers.4.attention.query_key_value.bias\n",
      "gpt_neox.layers.4.attention.dense.weight\n",
      "gpt_neox.layers.4.attention.dense.bias\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.5.attention.query_key_value.weight\n",
      "gpt_neox.layers.5.attention.query_key_value.bias\n",
      "gpt_neox.layers.5.attention.dense.weight\n",
      "gpt_neox.layers.5.attention.dense.bias\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.bias\n",
      "4\n",
      "gpt_neox.layers.0.attention.query_key_value.weight\n",
      "gpt_neox.layers.0.attention.query_key_value.bias\n",
      "gpt_neox.layers.0.attention.dense.weight\n",
      "gpt_neox.layers.0.attention.dense.bias\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.1.attention.query_key_value.weight\n",
      "gpt_neox.layers.1.attention.query_key_value.bias\n",
      "gpt_neox.layers.1.attention.dense.weight\n",
      "gpt_neox.layers.1.attention.dense.bias\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.2.attention.query_key_value.weight\n",
      "gpt_neox.layers.2.attention.query_key_value.bias\n",
      "gpt_neox.layers.2.attention.dense.weight\n",
      "gpt_neox.layers.2.attention.dense.bias\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.3.attention.query_key_value.weight\n",
      "gpt_neox.layers.3.attention.query_key_value.bias\n",
      "gpt_neox.layers.3.attention.dense.weight\n",
      "gpt_neox.layers.3.attention.dense.bias\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.4.attention.query_key_value.weight\n",
      "gpt_neox.layers.4.attention.query_key_value.bias\n",
      "gpt_neox.layers.4.attention.dense.weight\n",
      "gpt_neox.layers.4.attention.dense.bias\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.5.attention.query_key_value.weight\n",
      "gpt_neox.layers.5.attention.query_key_value.bias\n",
      "gpt_neox.layers.5.attention.dense.weight\n",
      "gpt_neox.layers.5.attention.dense.bias\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.bias\n",
      "5\n",
      "gpt_neox.layers.0.attention.query_key_value.weight\n",
      "gpt_neox.layers.0.attention.query_key_value.bias\n",
      "gpt_neox.layers.0.attention.dense.weight\n",
      "gpt_neox.layers.0.attention.dense.bias\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.1.attention.query_key_value.weight\n",
      "gpt_neox.layers.1.attention.query_key_value.bias\n",
      "gpt_neox.layers.1.attention.dense.weight\n",
      "gpt_neox.layers.1.attention.dense.bias\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.2.attention.query_key_value.weight\n",
      "gpt_neox.layers.2.attention.query_key_value.bias\n",
      "gpt_neox.layers.2.attention.dense.weight\n",
      "gpt_neox.layers.2.attention.dense.bias\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.3.attention.query_key_value.weight\n",
      "gpt_neox.layers.3.attention.query_key_value.bias\n",
      "gpt_neox.layers.3.attention.dense.weight\n",
      "gpt_neox.layers.3.attention.dense.bias\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.4.attention.query_key_value.weight\n",
      "gpt_neox.layers.4.attention.query_key_value.bias\n",
      "gpt_neox.layers.4.attention.dense.weight\n",
      "gpt_neox.layers.4.attention.dense.bias\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.bias\n",
      "gpt_neox.layers.5.attention.query_key_value.weight\n",
      "gpt_neox.layers.5.attention.query_key_value.bias\n",
      "gpt_neox.layers.5.attention.dense.weight\n",
      "gpt_neox.layers.5.attention.dense.bias\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.weight\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.bias\n",
      "Total number of parameters: 75589632\n",
      "Total memory size: 288.3515625 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for key, val in model_metrics.items():\n",
    "    print(key)\n",
    "    total_sum = 0 \n",
    "    for k, v in val.items():\n",
    "        print(k)\n",
    "        if isinstance(v, torch.Tensor): \n",
    "            total_sum += v.numel()\n",
    "        elif isinstance(v, dict):\n",
    "            for kk, vv in v.items():\n",
    "                print(kk)\n",
    "                if isinstance(vv, torch.Tensor): \n",
    "                    total_sum += vv.numel()\n",
    "                else:\n",
    "                    print(kk, vv)\n",
    "\n",
    "    print('Total number of parameters:', total_sum)\n",
    "    print('Total memory size:', total_sum * 4 / 1024 / 1024, 'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt_neox.layers.0.attention.query_key_value': tensor([[-0.1002,  0.5316, -0.3169,  ..., -0.7905,  0.1086, -0.8709],\n",
       "         [ 1.0063,  0.0190, -0.3028,  ..., -0.5302, -0.2370, -0.6362],\n",
       "         [-0.1666, -0.3279,  0.0215,  ...,  0.8039, -1.5459, -1.1745],\n",
       "         ...,\n",
       "         [ 0.5986,  0.2787, -0.5125,  ...,  0.0431, -0.0212, -0.3856],\n",
       "         [ 0.4669,  0.8417,  0.2269,  ...,  0.0930, -0.0229,  0.2580],\n",
       "         [ 0.7371,  0.3787, -0.7210,  ..., -0.2054, -0.3125, -0.4347]]),\n",
       " 'gpt_neox.layers.0.attention.dense': tensor([[ 0.0228, -0.1724, -0.2680,  ...,  0.1274,  0.1237, -0.1326],\n",
       "         [-0.4078, -0.2653,  0.0413,  ..., -0.2690, -0.4955, -0.0136],\n",
       "         [-0.1841,  0.3855,  0.3553,  ..., -0.1081,  0.0655,  0.3064],\n",
       "         ...,\n",
       "         [ 0.1304,  0.2610, -0.0012,  ...,  0.2352,  0.1033, -0.0114],\n",
       "         [ 0.0784, -0.0440,  0.3295,  ...,  0.2732,  0.0257, -0.0157],\n",
       "         [-0.2000,  0.4517,  0.2933,  ..., -0.2888, -0.3353,  0.0587]],\n",
       "        device='cuda:0'),\n",
       " 'gpt_neox.layers.0.mlp.dense_4h_to_h': tensor([[-0.1004,  0.1497,  0.2411,  ..., -0.2311, -0.1262, -0.3122],\n",
       "         [ 0.0849,  0.2188,  0.0176,  ..., -0.0602, -0.1150, -0.3614],\n",
       "         [ 0.1595,  0.0065, -0.0230,  ...,  0.0609,  0.1286,  0.1994],\n",
       "         ...,\n",
       "         [ 0.0626, -0.0734, -0.0776,  ..., -0.2623, -0.0042,  0.1487],\n",
       "         [-0.1303,  0.1834,  0.2118,  ...,  0.4644, -0.1070,  0.0237],\n",
       "         [-0.3239,  0.0642,  0.2120,  ..., -0.2163,  0.3153, -0.0772]]),\n",
       " 'gpt_neox.layers.1.attention.query_key_value': tensor([[-0.3833,  0.9428, -0.4314,  ..., -0.1567, -0.5047, -0.0434],\n",
       "         [-0.0046, -0.0092, -0.4722,  ...,  0.3102,  0.3701,  0.1283],\n",
       "         [ 0.1081,  0.5494,  0.2610,  ..., -0.1657,  0.4406, -0.2794],\n",
       "         ...,\n",
       "         [-0.4019, -0.5658,  0.1985,  ..., -0.3960,  0.7872, -0.0540],\n",
       "         [-0.3861, -0.1629,  0.0077,  ...,  0.0573,  0.9199,  0.9406],\n",
       "         [-0.2445,  0.0768,  0.0730,  ..., -0.1053, -0.0704,  0.4789]]),\n",
       " 'gpt_neox.layers.1.attention.dense': tensor([[-0.2474, -0.2082, -0.0442,  ...,  0.0791, -0.3249,  0.0293],\n",
       "         [ 0.1846, -0.1661,  0.1667,  ...,  0.3080, -0.3316, -0.2615],\n",
       "         [ 0.0608, -0.2522,  0.2474,  ...,  0.1063, -0.0127,  0.0042],\n",
       "         ...,\n",
       "         [ 0.0218,  0.2034,  0.0729,  ...,  0.6093, -0.0453,  0.0507],\n",
       "         [-0.2397, -0.1260,  0.1640,  ...,  0.1777, -0.0165, -0.0606],\n",
       "         [ 0.0042,  0.3034,  0.3709,  ..., -0.0628,  0.2006, -0.3375]],\n",
       "        device='cuda:0'),\n",
       " 'gpt_neox.layers.1.mlp.dense_4h_to_h': tensor([[-0.0236,  0.1837, -0.3527,  ..., -0.3018, -0.4300,  0.0756],\n",
       "         [ 0.0168,  0.2826,  0.0069,  ..., -0.3083, -0.1876,  0.0118],\n",
       "         [-0.0931,  0.3589, -0.3081,  ..., -0.0234, -0.1486,  0.2324],\n",
       "         ...,\n",
       "         [-0.3487,  0.0902, -0.3104,  ..., -0.0606, -0.3017,  0.1615],\n",
       "         [-0.2123,  0.4772, -0.0059,  ..., -0.1204, -0.0077,  0.1615],\n",
       "         [ 0.0631,  0.3351, -0.1467,  ...,  0.1903,  0.1128,  0.6957]]),\n",
       " 'gpt_neox.layers.2.attention.query_key_value': tensor([[-1.4604, -0.0280,  0.5463,  ..., -0.0471,  0.0662, -0.6222],\n",
       "         [-0.4649, -0.4727,  0.7748,  ...,  0.0868,  0.5177, -0.5321],\n",
       "         [-0.4241, -0.2399,  0.7365,  ..., -0.2916, -1.2845, -0.1683],\n",
       "         ...,\n",
       "         [ 0.7666, -0.3921,  0.3954,  ...,  0.4757, -0.3576,  0.0210],\n",
       "         [ 0.0059, -0.8962, -0.5244,  ..., -0.5057, -0.2948, -0.9202],\n",
       "         [-0.2484,  0.0977,  0.4418,  ..., -0.0720, -0.4629, -0.3730]]),\n",
       " 'gpt_neox.layers.2.attention.dense': tensor([[-0.0979, -0.1246, -0.0069,  ...,  0.2319,  0.0982,  0.2365],\n",
       "         [ 0.0642,  0.1406, -0.0027,  ..., -0.0661, -0.2796, -0.3619],\n",
       "         [-0.4181, -0.0351, -0.1787,  ..., -0.3412,  0.0641,  0.1963],\n",
       "         ...,\n",
       "         [-0.4965, -0.0943, -0.1337,  ..., -0.0577,  0.3879, -0.0084],\n",
       "         [-0.4698,  0.1146,  0.0323,  ..., -0.1939, -0.2385, -0.3274],\n",
       "         [ 0.0519,  0.0704,  0.0007,  ..., -0.1690, -0.2494, -0.1427]],\n",
       "        device='cuda:0'),\n",
       " 'gpt_neox.layers.2.mlp.dense_4h_to_h': tensor([[ 1.6634e-01,  4.1719e-01, -1.4899e-01,  ..., -2.4342e-01,\n",
       "           1.7788e-01,  5.1338e-02],\n",
       "         [-1.5249e-01,  2.3687e-01, -2.3498e-01,  ...,  1.9466e-01,\n",
       "           3.9609e-01, -1.5400e-01],\n",
       "         [-3.6648e-02,  3.1953e-01,  1.9206e-01,  ..., -3.9420e-01,\n",
       "           2.6907e-01,  8.2409e-02],\n",
       "         ...,\n",
       "         [-1.1676e-01,  3.6169e-01, -2.7162e-04,  ..., -5.7895e-03,\n",
       "          -2.6785e-01, -3.4733e-01],\n",
       "         [ 6.6116e-01,  2.9471e-01, -1.7424e-01,  ...,  9.0245e-02,\n",
       "           1.5053e-02,  5.5954e-02],\n",
       "         [-3.3758e-02, -9.3773e-02,  1.6807e-01,  ..., -1.2945e-01,\n",
       "          -1.1156e-01,  2.3831e-02]]),\n",
       " 'gpt_neox.layers.3.attention.query_key_value': tensor([[-0.4548,  0.0032,  0.5036,  ..., -0.3797, -0.4130, -0.1683],\n",
       "         [-0.3633, -0.5079,  0.9299,  ..., -0.3242, -0.5372, -0.0424],\n",
       "         [-0.5870,  0.8576, -0.7446,  ..., -1.9329,  0.4317,  1.3270],\n",
       "         ...,\n",
       "         [-0.3226, -0.2637,  0.1946,  ...,  0.2017, -0.1373, -0.0182],\n",
       "         [ 0.1617, -0.1480,  1.7534,  ..., -0.3289,  0.4703,  0.1465],\n",
       "         [-0.4167, -0.4071,  0.7564,  ..., -0.6719,  0.5649, -0.5597]]),\n",
       " 'gpt_neox.layers.3.attention.dense': tensor([[ 0.2124, -0.0431, -0.2850,  ...,  0.2917,  0.1273, -0.1262],\n",
       "         [ 0.2413, -0.3658, -0.2048,  ...,  0.0467,  0.0725, -0.1933],\n",
       "         [-0.0615, -0.4394, -0.0885,  ...,  0.0162, -0.0426,  0.0495],\n",
       "         ...,\n",
       "         [-0.3643, -0.1713, -0.1295,  ...,  0.2878,  0.0542,  0.0286],\n",
       "         [-0.1259, -0.6432, -0.0033,  ...,  0.1320,  0.0943,  0.2497],\n",
       "         [ 0.0788, -0.4950, -0.1665,  ..., -0.0806,  0.0803,  0.4538]],\n",
       "        device='cuda:0'),\n",
       " 'gpt_neox.layers.3.mlp.dense_4h_to_h': tensor([[ 0.0378,  0.0366, -0.0280,  ..., -0.0020, -0.1436,  0.3061],\n",
       "         [ 0.1726, -0.2149, -0.0446,  ...,  0.1070, -0.0571,  0.6672],\n",
       "         [ 0.4938, -0.2477, -0.1630,  ..., -0.0520,  0.1709,  0.1827],\n",
       "         ...,\n",
       "         [ 0.0482, -0.0010,  0.2083,  ..., -0.1815, -0.0287,  0.4081],\n",
       "         [ 0.0776, -0.4479,  0.0745,  ..., -0.1283,  0.4592, -0.1121],\n",
       "         [ 0.0586,  0.0476,  0.0818,  ..., -0.2291,  0.6385,  0.2472]]),\n",
       " 'gpt_neox.layers.4.attention.query_key_value': tensor([[-0.7862, -0.3742,  0.3063,  ...,  1.4311, -0.0099, -0.2873],\n",
       "         [-0.5834,  0.1695,  0.9265,  ...,  0.5659, -0.3241, -0.0908],\n",
       "         [-1.3002,  0.7108, -0.1470,  ...,  1.0301,  0.8322, -1.2549],\n",
       "         ...,\n",
       "         [ 0.4522,  0.0552, -0.5274,  ...,  0.7134,  0.4049, -0.2381],\n",
       "         [-0.4445,  1.3078,  0.5596,  ...,  0.7869, -0.1209,  1.4989],\n",
       "         [ 0.3576,  0.7901,  0.4145,  ...,  0.1322, -0.0025, -0.7524]]),\n",
       " 'gpt_neox.layers.4.attention.dense': tensor([[ 0.0945,  0.3164, -0.2993,  ...,  0.1380, -0.0962, -0.1194],\n",
       "         [-0.1272,  0.1287, -0.3527,  ..., -0.0785, -0.1500,  0.2618],\n",
       "         [-0.0740,  0.2141, -0.5403,  ..., -0.0878,  0.1988, -0.1009],\n",
       "         ...,\n",
       "         [ 0.1143,  0.1383, -0.0885,  ...,  0.3300, -0.0945, -0.2405],\n",
       "         [-0.0987, -0.3013,  0.1784,  ..., -0.0514,  0.0157,  0.0538],\n",
       "         [ 0.1627, -0.0952,  0.2696,  ...,  0.0200, -0.3598,  0.0861]],\n",
       "        device='cuda:0'),\n",
       " 'gpt_neox.layers.4.mlp.dense_4h_to_h': tensor([[-0.0400, -0.1038, -0.0147,  ...,  0.0127, -0.2391,  0.2862],\n",
       "         [-0.1415, -0.0437, -0.0668,  ...,  0.2311,  0.1804, -0.1441],\n",
       "         [-0.2955,  0.1455,  0.0117,  ..., -0.0305,  0.0662,  0.4699],\n",
       "         ...,\n",
       "         [-0.1563,  0.0521,  0.1963,  ...,  0.2950, -0.2743,  0.0511],\n",
       "         [-0.1210, -0.1439,  0.1689,  ...,  0.1921,  0.0101, -0.3225],\n",
       "         [-0.1670,  0.2348,  0.5998,  ...,  0.4557, -0.0536, -0.1184]]),\n",
       " 'gpt_neox.layers.5.attention.query_key_value': tensor([[ 4.1517e-01, -2.2523e-01, -8.7538e-01,  ...,  6.1910e-01,\n",
       "          -7.3684e-04,  2.8732e-01],\n",
       "         [ 1.4076e-01,  2.5589e-01,  6.6018e-02,  ...,  3.6456e-01,\n",
       "          -2.9552e-01,  9.4846e-01],\n",
       "         [-1.0372e+00, -5.4846e-01,  6.3368e-01,  ...,  2.1095e-01,\n",
       "          -3.3659e-01,  5.7547e-02],\n",
       "         ...,\n",
       "         [ 7.2853e-02, -1.0217e+00, -1.6295e-01,  ...,  5.3574e-01,\n",
       "           8.6822e-02, -2.7270e-01],\n",
       "         [-3.2754e-01, -6.3669e-01,  4.1263e-01,  ...,  2.8077e-03,\n",
       "           6.3857e-01,  1.3706e+00],\n",
       "         [-7.0160e-01, -6.1764e-01, -1.0717e-01,  ...,  8.6117e-01,\n",
       "           6.5139e-01,  1.9306e-01]]),\n",
       " 'gpt_neox.layers.5.attention.dense': tensor([[-0.0728,  0.2060,  0.3110,  ..., -0.0888,  0.1042,  0.3116],\n",
       "         [-0.4627,  0.2573,  0.3330,  ...,  0.0210,  0.0937, -0.0041],\n",
       "         [-0.1771,  0.2710,  0.2820,  ..., -0.3119, -0.0076, -0.0035],\n",
       "         ...,\n",
       "         [-0.0582, -0.1213,  0.0980,  ...,  0.2152, -0.1881, -0.0167],\n",
       "         [ 0.1240,  0.3842, -0.1069,  ..., -0.1911, -0.3599, -0.1214],\n",
       "         [ 0.0524,  0.4458,  0.0650,  ..., -0.2847, -0.0428, -0.2278]],\n",
       "        device='cuda:0'),\n",
       " 'gpt_neox.layers.5.mlp.dense_4h_to_h': tensor([[ 0.1341, -0.1999,  0.3274,  ...,  0.1555, -0.1493, -0.0148],\n",
       "         [-0.0547, -0.4734, -0.0753,  ...,  0.1509,  0.0440, -0.1720],\n",
       "         [-0.0747, -0.2561,  0.1145,  ..., -0.2583,  0.1639,  0.0370],\n",
       "         ...,\n",
       "         [ 0.2248, -0.3197,  0.0566,  ..., -0.4743, -0.1040, -0.1487],\n",
       "         [ 0.0136, -0.2087,  0.1587,  ...,  0.0217,  0.1577, -0.3126],\n",
       "         [-0.0370, -0.1916,  0.1078,  ...,  0.0216, -0.2493,  0.1241]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 77/77 [00:01<00:00, 73.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initial constants\n",
    "\n",
    "checkpoint_dataset = load_dataset(\"rdiehlmartinez/pythia-pile-presampled\", \"checkpoints\", split='train', num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_steps = list(set(checkpoint_dataset['step']))\n",
    "ordered_steps.sort()\n",
    "step_to_start_index = {step: i*1024 for i, step in enumerate(ordered_steps)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_steps[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[142001,\n",
       " 142002,\n",
       " 142003,\n",
       " 142004,\n",
       " 142005,\n",
       " 142995,\n",
       " 142996,\n",
       " 142997,\n",
       " 142998,\n",
       " 142999]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_steps[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_batch(step):\n",
    "\n",
    "    assert(step in step_to_start_index), f\"Step {step} not valid checkpoint step.\"\n",
    "    start_idx = step_to_start_index[step]\n",
    "    end_idx = start_idx + 1024\n",
    "\n",
    "    batch = checkpoint_dataset[start_idx:end_idx]['ids']\n",
    "    steps = checkpoint_dataset[start_idx:end_idx]['step']\n",
    "\n",
    "    return (batch, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Step 143000 not valid checkpoint step.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m curr_batch, steps \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m143_000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m, in \u001b[0;36mget_data_batch\u001b[0;34m(step)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data_batch\u001b[39m(step):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m(step \u001b[38;5;129;01min\u001b[39;00m step_to_start_index), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not valid checkpoint step.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     start_idx \u001b[38;5;241m=\u001b[39m step_to_start_index[step]\n\u001b[1;32m      5\u001b[0m     end_idx \u001b[38;5;241m=\u001b[39m start_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1024\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Step 143000 not valid checkpoint step."
     ]
    }
   ],
   "source": [
    "curr_batch, steps = get_data_batch(143_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000]\n"
     ]
    }
   ],
   "source": [
    "print(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenStateSaver:\n",
    "    \"\"\"\n",
    "    Class to save the hidden states of the model at a given checkpoint step. \n",
    "    \"\"\"\n",
    "    def __init__(self, checkpoint_step: int, model_size: int):\n",
    "        self.checkpoint_step = checkpoint_step\n",
    "        self.model_size = model_size\n",
    "\n",
    "        self.checkpoint_activations  = {}\n",
    "\n",
    "        self.checkpoint_weights = {} \n",
    "\n",
    "        self.checkpoint_gradients = {}\n",
    "\n",
    "        # compute valid gradient steps (i.e. the steps around the checkpoint step for \n",
    "        # which we want to compute the gradient)\n",
    "        # NOTE: the valid amount of steps is 5 below or 5 above the checkpoint step\n",
    "        self.valid_gradient_steps = list(\n",
    "            range(max(0, checkpoint_step-5), min(checkpoint_step+6, 143_000))\n",
    "        ) \n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"HiddenStateSaver(checkpoint_step={self.checkpoint_step}, model_size={self.model_size})\"\n",
    "\n",
    "    def get_forward_hook(self, module_name,):\n",
    "        def _forward_hook(module, module_in, module_out):\n",
    "\n",
    "            if \"attention.query_key_value\" in module_name:\n",
    "                hidden_states_out = module_out[..., 2*module_out.shape[-1]//3:][:, -1, :].detach().cpu()\n",
    "\n",
    "            elif \"attention.dense\" in module_name:\n",
    "                # Get name of the qkv module in the same layer \n",
    "                qkv_module_name = module._global_module_name.replace(\"attention.dense\", \"attention.query_key_value\")\n",
    "                previous_module_output = self.checkpoint_activations[qkv_module_name]\n",
    "\n",
    "                curr_batch_size = module_out.shape[0]\n",
    "                previous_module_output = previous_module_output[-curr_batch_size:].to('cuda')\n",
    "\n",
    "                # NOTE: need to call directly to not activate module hook \n",
    "                hidden_states_out = F.linear(previous_module_output, module.weight, module.bias)\n",
    "\n",
    "            elif \"mlp.dense_4h_to_h\" in module_name:\n",
    "                hidden_states_out = module_out.detach().cpu()[:, -1, :]\n",
    "\n",
    "            # check if there is already a key for the module name \n",
    "            if module_name not in self.checkpoint_activations:\n",
    "                # if there is no key, then we create a new key and store the hidden states\n",
    "                self.checkpoint_activations[module_name] = hidden_states_out\n",
    "\n",
    "                # extract the weight matrix just once \n",
    "                weight_matrix = module.weight.detach().cpu()\n",
    "                self.checkpoint_weights[module_name] = weight_matrix\n",
    "            else:\n",
    "                # if there is already a key, then we concatenate the new hidden states to the existing ones\n",
    "                self.checkpoint_activations[module_name] = torch.cat(\n",
    "                    (self.checkpoint_activations[module_name], hidden_states_out)\n",
    "                )\n",
    "        \n",
    "        return _forward_hook\n",
    "\n",
    "    def get_backward_hook(self, module_name,):\n",
    "        def _backward_hook(grad):\n",
    "            # NOTE: grad_output is a single-entry tuple, with the gradient of the output of the module\n",
    "            # these gradients have dimension (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "            gradient_matrix = grad.detach().cpu()\n",
    "\n",
    "            # check if there is already a key for the module name\n",
    "            if module_name not in self.checkpoint_gradients:\n",
    "                # if there is no key, then we create a new key and store the hidden states\n",
    "                self.checkpoint_gradients[module_name] = {}\n",
    "\n",
    "            grad_step = len(self.checkpoint_gradients[module_name])\n",
    "\n",
    "            # store the gradient matrix\n",
    "            self.checkpoint_gradients[module_name][grad_step] = gradient_matrix\n",
    "\n",
    "        return _backward_hook\n",
    "\n",
    "    def cleanup_hidden_states(self):\n",
    "        last_layer_name = list(self.checkpoint_hidden_states.keys())[-1]\n",
    "        last_layer = self.checkpoint_hidden_states[last_layer_name]\n",
    "        last_layer_samples = last_layer.shape[0]\n",
    "\n",
    "        for layer_name, layer in self.checkpoint_hidden_states.items():\n",
    "            if layer.shape[0] > last_layer_samples:\n",
    "                self.checkpoint_hidden_states[layer_name] = layer[:last_layer_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['ids', 'step'],\n",
      "    num_rows: 1709056\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "valid_checkpoint_steps = set(checkpoint_dataset['step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_steps = [0, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1000, ]\n",
    "checkpoint_steps.extend([3000 + (i * 10000) for i in range(0, 15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current step:  0\n",
      "\t  0\n",
      "\t  1\n",
      "\t  2\n",
      "\t  3\n",
      "\t  4\n",
      "\t  5\n",
      "Current step:  1\n",
      "\t  0\n",
      "\t  1\n",
      "\t  2\n",
      "\t  3\n",
      "\t  4\n",
      "\t  5\n",
      "\t  6\n",
      "Current step:  2\n",
      "\t  0\n",
      "\t  1\n",
      "\t  2\n",
      "\t  3\n",
      "\t  4\n",
      "\t  5\n",
      "\t  6\n",
      "\t  7\n",
      "Current step:  4\n",
      "\t  0\n",
      "\t  1\n",
      "\t  2\n",
      "\t  3\n",
      "\t  4\n",
      "\t  5\n",
      "\t  6\n",
      "\t  7\n",
      "\t  8\n",
      "\t  9\n",
      "Current step:  8\n",
      "\t  3\n",
      "\t  4\n",
      "\t  5\n",
      "\t  6\n",
      "\t  7\n",
      "\t  8\n",
      "\t  9\n",
      "\t  10\n",
      "\t  11\n",
      "\t  12\n",
      "\t  13\n",
      "Current step:  16\n",
      "\t  11\n",
      "\t  12\n",
      "\t  13\n",
      "\t  14\n",
      "\t  15\n",
      "\t  16\n",
      "\t  17\n",
      "\t  18\n",
      "\t  19\n",
      "\t  20\n",
      "\t  21\n",
      "Current step:  32\n",
      "\t  27\n",
      "\t  28\n",
      "\t  29\n",
      "\t  30\n",
      "\t  31\n",
      "\t  32\n",
      "\t  33\n",
      "\t  34\n",
      "\t  35\n",
      "\t  36\n",
      "\t  37\n",
      "Current step:  64\n",
      "\t  59\n",
      "\t  60\n",
      "\t  61\n",
      "\t  62\n",
      "\t  63\n",
      "\t  64\n",
      "\t  65\n",
      "\t  66\n",
      "\t  67\n",
      "\t  68\n",
      "\t  69\n",
      "Current step:  128\n",
      "\t  123\n",
      "\t  124\n",
      "\t  125\n",
      "\t  126\n",
      "\t  127\n",
      "\t  128\n",
      "\t  129\n",
      "\t  130\n",
      "\t  131\n",
      "\t  132\n",
      "\t  133\n",
      "Current step:  256\n",
      "\t  251\n",
      "\t  252\n",
      "\t  253\n",
      "\t  254\n",
      "\t  255\n",
      "\t  256\n",
      "\t  257\n",
      "\t  258\n",
      "\t  259\n",
      "\t  260\n",
      "\t  261\n",
      "Current step:  512\n",
      "\t  507\n",
      "\t  508\n",
      "\t  509\n",
      "\t  510\n",
      "\t  511\n",
      "\t  512\n",
      "\t  513\n",
      "\t  514\n",
      "\t  515\n",
      "\t  516\n",
      "\t  517\n",
      "Current step:  1000\n",
      "\t  995\n",
      "\t  996\n",
      "\t  997\n",
      "\t  998\n",
      "\t  999\n",
      "\t  1000\n",
      "\t  1001\n",
      "\t  1002\n",
      "\t  1003\n",
      "\t  1004\n",
      "\t  1005\n",
      "Current step:  3000\n",
      "\t  2995\n",
      "\t  2996\n",
      "\t  2997\n",
      "\t  2998\n",
      "\t  2999\n",
      "\t  3000\n",
      "\t  3001\n",
      "\t  3002\n",
      "\t  3003\n",
      "\t  3004\n",
      "\t  3005\n",
      "Current step:  13000\n",
      "\t  12995\n",
      "\t  12996\n",
      "\t  12997\n",
      "\t  12998\n",
      "\t  12999\n",
      "\t  13000\n",
      "\t  13001\n",
      "\t  13002\n",
      "\t  13003\n",
      "\t  13004\n",
      "\t  13005\n",
      "Current step:  23000\n",
      "\t  22995\n",
      "\t  22996\n",
      "\t  22997\n",
      "\t  22998\n",
      "\t  22999\n",
      "\t  23000\n",
      "\t  23001\n",
      "\t  23002\n",
      "\t  23003\n",
      "\t  23004\n",
      "\t  23005\n",
      "Current step:  33000\n",
      "\t  32995\n",
      "\t  32996\n",
      "\t  32997\n",
      "\t  32998\n",
      "\t  32999\n",
      "\t  33000\n",
      "\t  33001\n",
      "\t  33002\n",
      "\t  33003\n",
      "\t  33004\n",
      "\t  33005\n",
      "Current step:  43000\n",
      "\t  42995\n",
      "\t  42996\n",
      "\t  42997\n",
      "\t  42998\n",
      "\t  42999\n",
      "\t  43000\n",
      "\t  43001\n",
      "\t  43002\n",
      "\t  43003\n",
      "\t  43004\n",
      "\t  43005\n",
      "Current step:  53000\n",
      "\t  52995\n",
      "\t  52996\n",
      "\t  52997\n",
      "\t  52998\n",
      "\t  52999\n",
      "\t  53000\n",
      "\t  53001\n",
      "\t  53002\n",
      "\t  53003\n",
      "\t  53004\n",
      "\t  53005\n",
      "Current step:  63000\n",
      "\t  62995\n",
      "\t  62996\n",
      "\t  62997\n",
      "\t  62998\n",
      "\t  62999\n",
      "\t  63000\n",
      "\t  63001\n",
      "\t  63002\n",
      "\t  63003\n",
      "\t  63004\n",
      "\t  63005\n",
      "Current step:  73000\n",
      "\t  72995\n",
      "\t  72996\n",
      "\t  72997\n",
      "\t  72998\n",
      "\t  72999\n",
      "\t  73000\n",
      "\t  73001\n",
      "\t  73002\n",
      "\t  73003\n",
      "\t  73004\n",
      "\t  73005\n",
      "Current step:  83000\n",
      "\t  82995\n",
      "\t  82996\n",
      "\t  82997\n",
      "\t  82998\n",
      "\t  82999\n",
      "\t  83000\n",
      "\t  83001\n",
      "\t  83002\n",
      "\t  83003\n",
      "\t  83004\n",
      "\t  83005\n",
      "Current step:  93000\n",
      "\t  92995\n",
      "\t  92996\n",
      "\t  92997\n",
      "\t  92998\n",
      "\t  92999\n",
      "\t  93000\n",
      "\t  93001\n",
      "\t  93002\n",
      "\t  93003\n",
      "\t  93004\n",
      "\t  93005\n",
      "Current step:  103000\n",
      "\t  102995\n",
      "\t  102996\n",
      "\t  102997\n",
      "\t  102998\n",
      "\t  102999\n",
      "\t  103000\n",
      "\t  103001\n",
      "\t  103002\n",
      "\t  103003\n",
      "\t  103004\n",
      "\t  103005\n",
      "Current step:  113000\n",
      "\t  112995\n",
      "\t  112996\n",
      "\t  112997\n",
      "\t  112998\n",
      "\t  112999\n",
      "\t  113000\n",
      "\t  113001\n",
      "\t  113002\n",
      "\t  113003\n",
      "\t  113004\n",
      "\t  113005\n",
      "Current step:  123000\n",
      "\t  122995\n",
      "\t  122996\n",
      "\t  122997\n",
      "\t  122998\n",
      "\t  122999\n",
      "\t  123000\n",
      "\t  123001\n",
      "\t  123002\n",
      "\t  123003\n",
      "\t  123004\n",
      "\t  123005\n",
      "Current step:  133000\n",
      "\t  132995\n",
      "\t  132996\n",
      "\t  132997\n",
      "\t  132998\n",
      "\t  132999\n",
      "\t  133000\n",
      "\t  133001\n",
      "\t  133002\n",
      "\t  133003\n",
      "\t  133004\n",
      "\t  133005\n",
      "Current step:  143000\n",
      "\t  142995\n",
      "\t  142996\n",
      "\t  142997\n",
      "\t  142998\n",
      "\t  142999\n"
     ]
    }
   ],
   "source": [
    "diff_factor = 5 \n",
    "for step in checkpoint_steps: \n",
    "    print(\"Current step: \", step)\n",
    "    for _step in range(max(0, step-diff_factor), min(143_000, step+diff_factor+1)):\n",
    "        if _step not in valid_checkpoint_steps:\n",
    "            print(\"OOPS \", _step)\n",
    "        print(\"\\t \", _step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f65ccf69420>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rd654/.cache/pypoetry/virtualenvs/pretraining-playground-YJRPv6z4-py3.10/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "checkpoint_dataset['ids'][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "\n",
    "LIMIT_BATCH_SIZE = 10\n",
    "\n",
    "def get_data_batch(step: int):\n",
    "    start_idx = step * BATCH_SIZE\n",
    "    input_ids = torch.tensor(\n",
    "        checkpoint_dataset[start_idx:start_idx+BATCH_SIZE]['ids'],\n",
    "        device=torch.device('cuda')\n",
    "    )\n",
    "    return input_ids[:LIMIT_BATCH_SIZE]\n",
    "\n",
    "def get_gradient_batches(step: int): \n",
    "    \"\"\"\n",
    "    Return a generator of data batches for the valid gradient steps around the checkpoint step.\n",
    "    \"\"\"\n",
    "    valid_gradient_steps = list(\n",
    "        range(max(0, step-5), min(step+6, 143_000))\n",
    "    ) \n",
    "    return (get_data_batch(_step) for _step in valid_gradient_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7feba63a5420>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rd654/.cache/pypoetry/virtualenvs/pretraining-playground-YJRPv6z4-py3.10/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "batch = get_data_batch(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---  Setting up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current checkpoint step:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rd654/.cache/pypoetry/virtualenvs/pretraining-playground-YJRPv6z4-py3.10/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded in \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f885e93d420>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rd654/.cache/pypoetry/virtualenvs/pretraining-playground-YJRPv6z4-py3.10/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "model_size = \"70m\"\n",
    "target_layers =[\"attention.query_key_value\", \"attention.dense\", \"mlp.dense_4h_to_h\"]\n",
    "\n",
    "# for checkpoint_step in [0, 256, 113000]:\n",
    "\n",
    "checkpoint_step = 0 \n",
    "\n",
    "print(\"Current checkpoint step: \", checkpoint_step)\n",
    "\n",
    "model_checkpoint = GPTNeoXForCausalLM.from_pretrained(\n",
    "    f\"EleutherAI/pythia-{model_size}-deduped\",\n",
    "    revision=f\"step{checkpoint_step}\",\n",
    "    cache_dir=f\"./pythia-{model_size}-deduped/step{checkpoint_step}\",\n",
    ").to('cuda')\n",
    "\n",
    "print(\"model loaded in \")\n",
    "\n",
    "curr_step_batch = get_data_batch(checkpoint_step)\n",
    "\n",
    "print(\"batch loaded in \")\n",
    "print(len(curr_step_batch))\n",
    "\n",
    "hidden_state_saver = HiddenStateSaver(checkpoint_step, model_size)\n",
    "\n",
    "# setting up hooks \n",
    "for name, module in model_checkpoint.named_modules():\n",
    "    if any(layer in name for layer in target_layers):\n",
    "        module._global_module_name = name # track the name of the module relative to the global model\n",
    "        module.register_forward_hook(hidden_state_saver.get_forward_hook(name))\n",
    "        module.weight.register_hook(hidden_state_saver.get_backward_hook(name))\n",
    "\n",
    "# forward pass \n",
    "with torch.no_grad():\n",
    "    print(\"doing forward pass \")\n",
    "    model_checkpoint(curr_step_batch)\n",
    "\n",
    "print(\"doing backward passes \")\n",
    "for batch in get_gradient_batches(checkpoint_step):\n",
    "    model_checkpoint.zero_grad()\n",
    "    labels = batch.clone() # batch are just the input_ids\n",
    "    outputs = model_checkpoint(batch, labels=labels)\n",
    "    outputs['loss'].backward()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPTNeoXTokenizerFast.from_pretrained(\"EleutherAI/pythia-70m-deduped\", revision=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Memory Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum = 0 \n",
    "from functools import reduce\n",
    "for key, state in hidden_state_saver.checkpoint_weights.items():\n",
    "    # print(key, state.shape)\n",
    "    total_sum += reduce(lambda x,y: x*y, state.shape)\n",
    "print(\"TOTAL BYTES: \", total_sum * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum = 0 \n",
    "from functools import reduce\n",
    "for key, state in hidden_state_saver.checkpoint_activations.items():\n",
    "    # print(key, state.shape)\n",
    "    total_sum += reduce(lambda x,y: x*y, state.shape)\n",
    "print(\"TOTAL BYTES: \", total_sum * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum = 0 \n",
    "from functools import reduce\n",
    "for key, gradient_list in hidden_state_saver.checkpoint_gradients.items():\n",
    "    for grad in gradient_list:\n",
    "        # print(key, grad.shape)\n",
    "        total_sum += reduce(lambda x,y: x*y, grad.shape)\n",
    "print(\"TOTAL BYTES: \", total_sum * 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretraining-playground-YJRPv6z4-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
